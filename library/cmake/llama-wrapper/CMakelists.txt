cmake_minimum_required(VERSION 3.18)
project(llama_kmp_bridge)

# Force enable Threads when cross-compiling for iOS
if(CMAKE_SYSTEM_NAME STREQUAL "iOS")
    set(THREADS_PREFER_PTHREAD_FLAG ON)
    set(CMAKE_THREAD_LIBS_INIT "-lpthread")
    set(CMAKE_HAVE_THREADS_LIBRARY 1)
    set(CMAKE_USE_WIN32_THREADS_INIT 0)
    set(CMAKE_USE_PTHREADS_INIT 1)
endif()

find_package(Threads REQUIRED)

# Add llama.cpp as subdir
add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp llama-local-build EXCLUDE_FROM_ALL)

# llama.cpp core sources
file(GLOB LLAMA_SRC
        "${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp/src/llama.cpp"
        "${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp/src/llama-model-loader.cpp"
        "${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp/src/llama-log.cpp"
        "${CMAKE_CURRENT_SOURCE_DIR}/../../src/iosMain/cpp/llama_embed.cpp"
)

# Create llama_static
add_library(llama_static STATIC ${LLAMA_SRC})

target_include_directories(llama_static PUBLIC
        ${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp
        ${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp/include
        ${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp/ggml
        ${CMAKE_CURRENT_SOURCE_DIR}/../../../../llama.cpp/ggml/include
        ${CMAKE_CURRENT_SOURCE_DIR}/../../src/iosMain/c_interop/include
)

target_compile_features(llama_static PUBLIC cxx_std_17)
target_compile_definitions(llama_static PRIVATE GGML_STATIC GGML_NO_ACCELERATE)

set_target_properties(llama_static PROPERTIES
        ARCHIVE_OUTPUT_DIRECTORY "${CMAKE_BINARY_DIR}"
)