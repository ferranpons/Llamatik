---
title: "About"
image: "llamatik-icon-logo.png"
weight: 8
---

Kotlin-first llama.cpp integration for on-device and remote LLM inference.

### Features

* Kotlin Multiplatform: shared code across Android, iOS, and desktop
* Offline inference via llama.cpp (compiled with Kotlin/Native bindings)
* Remote inference via optional HTTP client (e.g. llamatik-server)
* Embeddings and text generation support
* Works with GGUF models (e.g. Mistral, Phi, LLaMA)
* Lightweight and dependency-free runtime
